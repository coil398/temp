人工智能
维基百科，自由的百科全书
（重定向自人工知能）
Ambox wikify.svg
	本条目部分链接不符合格式手冊規範。跨語言链接及章節標題等處的链接可能需要清理。（2015年12月11日）
請協助改善此條目。參見WP:LINKSTYLE、WP:MOSIW以了解細節。突出显示跨语言链接可以便于检查。
本文介紹的是计算机科學。關於斯蒂芬·斯皮爾伯格導演的一部電影，詳見「A.I.人工智慧」。
「人工智能」的各地常用別名
ArtificialFictionBrain.png
中国大陸 	人工智能
臺灣 	人工智慧
港澳 	人工智能
新馬 	人工智慧
日韓 	人工知能
越南 	智慧人造（人造智慧）

人工智能（英语：Artificial Intelligence, AI）亦稱機器智能，是指由人工製造出來的系統所表現出來的智能。通常人工智能是指通過普通電腦實現的智能。該詞同時也指研究這樣的智能系統是否能夠實現，以及如何實現的科學領域。

一般教材中的定义领域是“智能主体（intelligent agent）的研究与设计”[1]，智能主体是指一个可以观察周遭环境并作出行动以达致目标的系统。[2]约翰·麦卡锡于1955年的定义是[3]「制造智能机器的科学与工程。」[4]

人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。[5]

人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。AI的核心问题包括推理、知识、规划、学习、交流、感知、移动和操作物体的能力等。[6]強人工智能目前仍然是该领域的长远目标。[7]目前比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。

目录

    1 概論
    2 發展史
    3 研究課題
        3.1 演绎、推理和解决问题
        3.2 知識表示法
        3.3 规划
        3.4 學習
        3.5 自然語言處理
        3.6 運動和控制
        3.7 知覺
        3.8 社交
        3.9 創造力
        3.10 多元智能
        3.11 倫理管理
        3.12 經濟衝擊
    4 強人工智能和弱人工智能
        4.1 強人工智能
        4.2 弱人工智能
        4.3 對強人工智能的哲學爭論
    5 研究方法
        5.1 控制论与大脑模拟
        5.2 符号处理
        5.3 子符号方法
        5.4 统计学方法
        5.5 集成方法
    6 实际应用
    7 學科範疇
        7.1 涉及學科
        7.2 研究範疇
    8 應用領域
    9 參見
    10 注释
    11 参考文献
        11.1 教材
        11.2 人工智能历史
        11.3 其他
    12 扩展阅读
    13 站外鏈接

概論

人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」比較好理解，爭議性也不大。有時我們會要考慮什麼是人力所能及製造的，或者人自身的智能程度有沒有高到可以創造人工智能的地步，等等。但總的來說，「人工系統」就是通常意義下的人工系統。

關於什麼是「智能」，就問題多多了。這涉及到其它諸如意識（consciousness）、自我（self）、心靈（mind，包括無意識的精神（unconscious mind））等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是我們對我們自身智能的理解都非常有限，對構成人的智能的必要元素也瞭解有限，所以就很難定義什麼是「人工」製造的「智能」了。因此人工智能的研究往往涉及對人的智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。

人工智慧目前在計算機領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。
發展史
主条目：人工智能的历史
年代 	20世纪40年代 	20世纪50年代 	20世纪60年代 	20世纪70年代 	20世纪80年代 	20世纪90年代
計算機 	1945 計算機（ENIAC） 	1957 FORTRAN語言 				
人工智慧研究 		1953 博弈論
1956 达特矛斯会议 		1977 知識工程宣言 	1982 第五代電腦計劃開始 	1991 人工神经网络
人工智慧語言 			1960 LISP語言 	1973 PROLOG語言 		
知識表達 				1973 生產系統
1976 框架理論 		
專家系統 			1965 DENDRAL 	1975 MYCIN 	1980 Xcon 	
研究課題

目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。[6]
演绎、推理和解决问题

早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。[8]到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。[9]

对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。[10]

人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。[11]人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。
知識表示法
An ontology represents knowledge as a set of concepts within a domain and the relationships between those concepts.
主条目：知識表示和常識知識庫
规划
File:Hierarchical-control-system.svg
A hierarchical control system is a form of control system in which a set of devices and governing software is arranged in a hierarchy.

智能Agent必须能够制定目标和实现这些目标。[12]他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。[13] 在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。[14]但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。[15] 在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。[16]
學習
主条目：機器學習

机器学习的主要目的是为了从使用者和输入数据等处获得知识，从而可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。1956年，在最初的达特茅斯夏季会议上，雷蒙德索洛莫诺夫写了一篇关于不监视的概率性机器学习：一个归纳推理的机器。
自然語言處理
主条目：自然語言處理
運動和控制
主条目：機器人學
知覺
主条目：機器感知、計算機視覺和語音識別

機器感知[17]是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。計算機視覺[18]能夠分析影像輸入。另外還有語音識別[19]、人臉辨識和物體辨識。[20]
社交
主条目：情感計算
Kismet,一个具有表情等社交能力的机器人[21]

情感和社交技能對於一個智能agent是很重要的。首先，通過了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。
創造力
主条目：計算機創造力

一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域研究的包括了人工直覺和人工想像。
多元智能

大多數研究人員希望他們的研究最終將被納入一個具有多元智能（稱為強人工智慧），結合以上所有的技能並且超越大部分人類的能力。[7]有些人認為要達成以上目標，可能需要擬人化的特性，如人工意識或人工大腦。[22][23] 上述許多問題被認為是人工智慧完整性：為了解決其中一個問題，你必須解決全部的問題。即使一個簡單和特定的任務，如機器翻譯，要求機器按照作者的論點（推理），知道什麼是被人談論（知識），忠實地再現作者的意圖（情感計算）。因此，機器翻譯被認為是具有人工智慧完整性：它可能需要強人工智慧，就像是人類一樣。[24]
倫理管理

史蒂芬· 霍金、比爾蓋茲、 Elon Musk 、 Jaan Tallinn 以及 Nick Bostrom 等人都對於人工智慧技術的未來公開表示憂心[25]，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。[26]

DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。[27]

科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。[28]新南威爾斯大學（New South Wales）人工智慧的沃爾什（Toby Walsh）教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。[29]
經濟衝擊

據CNN財經網數字媒體未來學家兼Webbmedia集團創始人艾米‧韋伯（Amy Webb）；美國在線[30]...等紛紛預測一些即將被機器人取代的職業，日本野村總合研究所也與美國牛津大學的研究學者共同調查指出，10至20年後，日本有49%的職業(235種職業)可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，[31]例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊[30]。
強人工智能和弱人工智能

人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的約翰·麥卡錫在1956年的 達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。
強人工智能
主条目：強人工智慧

強人工智能觀點認為有可能製造出真正能推理（Reasoning）和解決問題（解决问题）的智能機器，並且，這樣的機器能將被認為是有知覺的，有自我意識的。強人工智能可以有兩類：

    類人的人工智能，即機器的思考和推理就像人的思維一樣。
    非類人的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。

弱人工智能

弱人工智能觀點認為不可能製造出能真正地推理和解決問題的智能機器，這些機器只不過看起來像是智能的，但是並不真正擁有智能，也不會有自主意識。

強人工智能的研究目前處於停滯不前的狀態下。人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別。就現下的人工智能研究領域來看，研究者已大量造出看起來像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。
對強人工智能的哲學爭論

「強人工智能」一詞最初是約翰·羅傑斯·希爾勒針對計算機和其它信息處理機器創造的，其定義為：

「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要運行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）

關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有思維和意識。

也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。

有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是看起來是智能的。基於這個論點，既然弱人工智能認為可以令機器看起來像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。

需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。
研究方法

目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。[32] 其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？[33] 智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？[34]

智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？[35] 約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，[36]这个概念后来被某些非GOFAI研究者采纳。[37][38]
控制论与大脑模拟
主条目：控制论和計算神經科學

20世纪40年代到50年代，许多研究者探索神经学，信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如格雷·華特(W. Grey Walter) 的烏龜（turtle）和約翰霍普金斯野獸（Johns Hopkins Beast）。 这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议.[39]直到1960,大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。
符号处理
主条目：GOFAI

当20世纪50年代，数字计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）[40]。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或神经网络的方法则置于次要[41]。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。

    认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰[42][43]。

    基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法[33]。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习[44]。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学[45]。

    “反逻辑”: 斯坦福大学的研究者 （如马文·闵斯基和西摩爾·派普特）[46]发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。羅杰·單克（Roger Schank）描述他们的“反逻辑”方法为“scruffy”[34]。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念[47]。

    基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件[48]。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式[49]。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。

子符号方法

1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题[35]。

    自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯（Rodney Brooks），否定符号人工智能而专注于机器人移动和求生等基本的工程问题。[50]他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。

    计算智能：1980年代中大衛·鲁姆哈特（David E. Rumelhart）等再次提出神经网络和联结主义[51]。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴[52]。

统计学方法

1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。Stuart J. Russell和Peter Norvig指出这些进步不亚于“革命”和“neats的成功”[53]。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标[54]。
集成方法

    智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言--如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。[2]

    agent体系结构和认知体系结构：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。[55]一个系统中包含符号和子符号部分的系统称为混合智能系统，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。 